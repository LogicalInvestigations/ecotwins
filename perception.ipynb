{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "IN_MAIN = __name__ == '__main__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infrastructure for copying notebooks\n",
    "if IN_COLAB and IN_MAIN:\n",
    "    home_dir = '/content/drive/MyDrive/Colab Notebooks/Ecosystems/v3'\n",
    "if IN_COLAB and IN_MAIN:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append(home_dir)\n",
    "    !pip -q install import-ipynb\n",
    "    %cd $home_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# import import_ipynb\n",
    "from ecotwins.utility import normalize, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from dataclasses import dataclass\n",
    "from dataclasses import field\n",
    "\n",
    "RADIUS = 4\n",
    "ORIGIN = np.array([0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Perception:\n",
    "\n",
    "    radius: float = RADIUS\n",
    "    origin: np.ndarray = field(default_factory=lambda: ORIGIN.copy())\n",
    "    steven_exponent: float = 0.6\n",
    "    reward_radius: float = 0.0\n",
    "    epsilon: float = np.sqrt(1e-1)\n",
    "    use_clip: bool = False\n",
    "    # Normally distributed noise in multi_direction and single_direction expressed\n",
    "    # as standard deviation.\n",
    "    direction_noise: float = 0 \n",
    "\n",
    "    # def __init__(self, radius=RADIUS, origin=ORIGIN, steven_exponent=0.6, reward_radius=0):\n",
    "    #     self.radius = radius\n",
    "    #     self.origin = origin.copy()\n",
    "    #     self.steven_exponent = steven_exponent\n",
    "    #     self.reward_radius = reward_radius\n",
    "\n",
    "    def __post_init__(self):\n",
    "       self._rng = default_rng() \n",
    "        \n",
    "    # Inverse square law\n",
    "\n",
    "    # The stimulus caused by one object at distance d.\n",
    "    # The closer the object the smaller the distance and the bigger the stimulus\n",
    "    # There is a max stimulus (max firing) that one object can cause. We set it to 1.\n",
    "\n",
    "    def stimulus(self, d, radius=None):\n",
    "        if radius is None:\n",
    "            radius = self.radius\n",
    "        # epsilon = 1e-1\n",
    "        # epsilon = np.sqrt(1e-1)\n",
    "        d = np.maximum(d - self.reward_radius, 0)\n",
    "        v = 1 / (self.epsilon + d) ** 2\n",
    "        v[d > radius] = 0\n",
    "        if self.use_clip:\n",
    "            v[v > 1] = 1\n",
    "        return v\n",
    "\n",
    "    # This function sums the stimuli from all the objects.\n",
    "    # def stimuli(distances, radius=RADIUS):\n",
    "    def stimuli(self, distances):\n",
    "        return self.stimulus(distances, self.radius).sum(axis=0)\n",
    "\n",
    "    # Weber-Fechner's law\n",
    "    def weber(self, stimuli):\n",
    "        return np.log(1 + stimuli)\n",
    "\n",
    "    # Steven's law\n",
    "    # def steven(stimuli,exponent=0.6): # The exponent for smell in humans is 0.6\n",
    "    def steven(self, stimuli):\n",
    "        return stimuli ** self.steven_exponent\n",
    "\n",
    "    # The sensation of the aggregated stimuli from objects inside the radius.\n",
    "    def sensation(self, objects, position=None, radius=None):\n",
    "        if position is None:\n",
    "            position = self.origin\n",
    "        if radius is None:\n",
    "            radius = self.radius\n",
    "        total = self.stimuli(distance(position, objects))\n",
    "        return self.weber(total)\n",
    "    \n",
    "    def _noise_rotation(self):\n",
    "        phi = self._rng.normal(scale=self.direction_noise) * 2 * np.pi\n",
    "        c, s = np.cos(phi), np.sin(phi)\n",
    "        return np.array([[c, -s], [s, c]])\n",
    "\n",
    "    # Computes the main direction to the objects within the radius, i.e. the sum of the perception vectors.\n",
    "    # Possible input to the policy network\n",
    "    def multi_direction(self, position, objects):\n",
    "        signals = self.stimulus(distance(position, objects)).reshape(-1, 1)\n",
    "        vector_sum = (signals * normalize(objects - position)).sum(\n",
    "            axis=0, keepdims=True\n",
    "        )  # ta inte bort dim 1x2\n",
    "        vector_sum = normalize(vector_sum).reshape(-1)\n",
    "        return np.dot(self._noise_rotation(), vector_sum)\n",
    "#         return normalize(vector_sum).reshape(-1)  # platta ut!\n",
    "\n",
    "    # Total smell from all objects\n",
    "    def total_intensity(self, position, objects):\n",
    "        if objects.size == 0:\n",
    "            return np.array([0.0])\n",
    "        return self.sensation(objects,position)\n",
    "\n",
    "    # Total smell from the closest object (disregarding all others)\n",
    "    def nearest_intensity(self, position, objects):\n",
    "        closest_point = self.closest(position, objects)\n",
    "        return self.total_intensity(position, closest_point)\n",
    "\n",
    "    # Filters out the visible objects from position.\n",
    "    def visible(self, position, objects, radius=None):\n",
    "        if radius is None:\n",
    "            radius = self.radius\n",
    "        return np.array([x for x in objects if distance(position, x) < radius])\n",
    "        # return objects[distance(position, objects) < radius] #Faster!\n",
    "\n",
    "    # This function returns the closest point to position in objects or the empty array\n",
    "    def closest(self, position, objects, radius=None):\n",
    "        if radius is None:\n",
    "            radius = self.radius\n",
    "        vis = self.visible(position, objects, radius)\n",
    "        if vis.shape[0] == 0:\n",
    "            return np.array([])  # Return an empty array if no objects are in sight\n",
    "        index = np.argmin(distance(position, vis))\n",
    "        return vis[index].reshape(1, 2)\n",
    "\n",
    "    # Computes the direction to the closest point from position among objects within the radius\n",
    "    # Returns the 0-vector if there are no such objects\n",
    "    def closest_direction(self, position, objects):\n",
    "        c = self.closest(position, objects)\n",
    "        if c.shape == (0,):\n",
    "            return np.zeros(2)\n",
    "        else:\n",
    "            v = normalize(c - position).reshape(-1)\n",
    "            return np.dot(self._noise_rotation(), v)\n",
    "#             return normalize(c - position).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perception()\n",
    "p.visible(np.array([.9,.9]), np.random.random((10,2)), radius=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted animal_classes.ipynb.\n",
      "Converted animation_helper.ipynb.\n",
      "Converted ecoenv.ipynb.\n",
      "Converted happiness.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted perception.ipynb.\n",
      "Converted reflex_agent.ipynb.\n",
      "Converted tyckande.ipynb.\n",
      "Converted utility.ipynb.\n",
      "Converted worlds.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
